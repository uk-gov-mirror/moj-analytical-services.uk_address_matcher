from uk_address_matcher.cleaning_v2.pipeline import (
    DuckDBPipeline,
)
from uk_address_matcher.cleaning_v2.cleaning_steps import (
    add_term_frequencies_to_address_tokens,
    canonicalise_postcode,
    clean_address_string_first_pass,
    clean_address_string_second_pass,
    derive_original_address_concat,
    generalised_token_aliases,
    final_column_order,
    first_unusual_token,
    move_common_end_tokens_to_field,
    parse_out_flat_position_and_letter,
    parse_out_numbers,
    remove_duplicate_end_tokens,
    separate_distinguishing_start_tokens_from_with_respect_to_adjacent_recrods,
    separate_unusual_tokens,
    split_numeric_tokens_to_cols,
    tokenise_address_without_numbers,
    trim_whitespace_address_and_postcode,
    use_first_unusual_token_if_no_numeric_token,
    upper_case_address_and_postcode,
)

from uk_address_matcher.cleaning.cleaning_steps import (
    add_term_frequencies_to_address_tokens as add_term_frequencies_to_address_tokens_v1,
    canonicalise_postcode as canonicalise_postcode_v1,
    clean_address_string_first_pass as clean_address_string_first_pass_v1,
    clean_address_string_second_pass as clean_address_string_second_pass_v1,
    derive_original_address_concat as derive_original_address_concat_v1,
    generalised_token_aliases as generalised_token_aliases_v1,
    final_column_order as final_column_order_v1,
    first_unusual_token as first_unusual_token_v1,
    move_common_end_tokens_to_field as move_common_end_tokens_to_field_v1,
    parse_out_flat_position_and_letter as parse_out_flat_position_and_letter_v1,
    parse_out_numbers as parse_out_numbers_v1,
    split_numeric_tokens_to_cols as split_numeric_tokens_to_cols_v1,
    tokenise_address_without_numbers as tokenise_address_without_numbers_v1,
    trim_whitespace_address_and_postcode as trim_whitespace_address_and_postcode_v1,
    upper_case_address_and_postcode as upper_case_address_and_postcode_v1,
    remove_duplicate_end_tokens as remove_duplicate_end_tokens_v1,
    separate_distinguishing_start_tokens_from_with_respect_to_adjacent_recrods as separate_distinguishing_start_tokens_from_with_respect_to_adjacent_recrods_v1,
    separate_unusual_tokens as separate_unusual_tokens_v1,
    use_first_unusual_token_if_no_numeric_token as use_first_unusual_token_if_no_numeric_token_v1,
)
from uk_address_matcher.cleaning.run_pipeline import run_pipeline

import duckdb
from time import perf_counter
from pandas.testing import assert_frame_equal

queue = [
    (trim_whitespace_address_and_postcode, trim_whitespace_address_and_postcode_v1),
    (canonicalise_postcode, canonicalise_postcode_v1),
    (upper_case_address_and_postcode, upper_case_address_and_postcode_v1),
    (clean_address_string_first_pass, clean_address_string_first_pass_v1),
    (remove_duplicate_end_tokens, remove_duplicate_end_tokens_v1),
    (derive_original_address_concat, derive_original_address_concat_v1),
    (
        separate_distinguishing_start_tokens_from_with_respect_to_adjacent_recrods,
        separate_distinguishing_start_tokens_from_with_respect_to_adjacent_recrods_v1,
    ),
    (generalised_token_aliases, generalised_token_aliases_v1),
    (parse_out_flat_position_and_letter, parse_out_flat_position_and_letter_v1),
    (parse_out_numbers, parse_out_numbers_v1),
    (clean_address_string_second_pass, clean_address_string_second_pass_v1),
    (split_numeric_tokens_to_cols, split_numeric_tokens_to_cols_v1),
    (tokenise_address_without_numbers, tokenise_address_without_numbers_v1),
    (
        add_term_frequencies_to_address_tokens,
        add_term_frequencies_to_address_tokens_v1,
    ),
    (move_common_end_tokens_to_field, move_common_end_tokens_to_field_v1),
    (first_unusual_token, first_unusual_token_v1),
    (
        use_first_unusual_token_if_no_numeric_token,
        use_first_unusual_token_if_no_numeric_token_v1,
    ),
    (separate_unusual_tokens, separate_unusual_tokens_v1),
    (final_column_order, final_column_order_v1),
]

con = duckdb.connect()

full_os_path = "secret_data/ord_surv/raw/add_gb_builtaddress_sorted_zstd.parquet"

sql = f"""
create or replace table os as
select
   uprn as unique_id,
   'canonical' as source_dataset,
   regexp_replace(fulladdress, ',[^,]*$', '') AS address_concat,
   postcode,
   latitude as lat,
   longitude as lng
from read_parquet('{full_os_path}')
limit 100

"""
con.execute(sql)
os_df = con.table("os")


pipe = DuckDBPipeline(con, os_df)

for v2, v1 in queue:
    pipe.add_step(v2())

t0 = perf_counter()
clean_v2 = pipe.run(pretty_print_sql=False).sort("unique_id")
clean_v2_df = clean_v2.df()
end_time = perf_counter()
print(f"Time taken: {end_time - t0:.2f} seconds")


queue_v2 = [v[1] for v in queue]
start_time = perf_counter()
clean_v1 = run_pipeline(
    os_df,
    con=con,
    cleaning_queue=queue_v2,
).sort("unique_id")
clean_v1_df = clean_v1.df()

end_time = perf_counter()
print(f"Time taken: {end_time - start_time:.2f} seconds")
clean_v1_df

# clean_v2.limit(10).show(max_width=100000)
# clean_v1.limit(10).show(max_width=100000)

assert_frame_equal(
    clean_v2_df,
    clean_v1_df,
    check_dtype=False,
    check_exact=False,
    rtol=1e-8,
    atol=1e-12,
)

from uk_address_matcher.cleaning_v2.cleaning_pipelines import (
    clean_data_on_the_fly,
    clean_data_using_precomputed_rel_tok_freq,
)
from uk_address_matcher.cleaning.cleaning_pipelines import (
    clean_data_on_the_fly as clean_data_on_the_fly_v1,
    clean_data_using_precomputed_rel_tok_freq as clean_data_using_precomputed_rel_tok_freq_v1,
)

v2_fly = clean_data_on_the_fly(
    address_table=os_df,
    con=con,
).df()

v1_fly = clean_data_on_the_fly_v1(
    address_table=os_df,
    con=con,
).df()

assert_frame_equal(
    v1_fly,
    v2_fly,
    check_dtype=False,
    check_exact=False,
    rtol=1e-8,
    atol=1e-12,
)

v2_fly_pre = clean_data_using_precomputed_rel_tok_freq(
    address_table=os_df,
    con=con,
).df()

v1_fly_pre = clean_data_using_precomputed_rel_tok_freq_v1(
    address_table=os_df,
    con=con,
).df()

assert_frame_equal(
    v1_fly_pre,
    v2_fly_pre,
    check_dtype=False,
    check_exact=False,
    rtol=1e-8,
    atol=1e-12,
)
